{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bcd59f5-468a-421c-a31e-b00a690ebeb7",
   "metadata": {},
   "source": [
    "Use Case\n",
    "\n",
    "Objective Statement:\n",
    "Get business insight about whether stroke will occure or not.\n",
    "To reduce risk in deciding to whom a stroke occur.\n",
    "To increase predicting efficiency by using different features of a person like age, gender, history of work and other medical conditions.\n",
    "\n",
    "Challenges:\n",
    "Large size of data, can not maintain by excel spreadsheet.\n",
    "Need several conditions to check at a same time.\n",
    "\n",
    "Methodology / Analytic Technique:\n",
    "Descriptive analysis\n",
    "Graph analysis\n",
    "\n",
    "Business Benefit:\n",
    "Helping Business Development Team to create predictions based on the characteristic for each patient.\n",
    "Know how to treat customer with specific medical condition.\n",
    "\n",
    "Expected Outcome:\n",
    "Know how many many patients are in risk of a stroke.\n",
    "\n",
    "Business Understanding:\n",
    "Why it is important to learn about stroke?\n",
    "Stroke is the second leading cause of death and disability worldwide. According to the WHO, 5 million people worldwide suffer a stroke every year. \n",
    "In the USA, someone has a stroke every 40 seconds and every 4 minutes, someone dies. The aftermath is devastating, with victims experiencing a wide range of disabling symptoms. \n",
    "The economic burden to the healthcare system in the US amounts to about $34 billion per year in the US. \n",
    "Who is affected?\n",
    "While there is no one, absolute risk factor for determining one’s chances of having a stroke, certain characteristics and factors may increase a person’s odds. \n",
    "It is estimated that 60 to 80% of strokes could be prevented through healthy lifestyle changes. \n",
    "The dataset will help to examine a multitude of variables to better understand which, if any, play a significant role in predicting the odds of having a stroke.\n",
    "Why do we care?\n",
    "Understanding one’s risk factors could help motivate an individual to better educate themselves on their chances of having a stroke, \n",
    "more closely monitor their health, make healthier choices, and ultimately decrease their overall risk of stroke. \n",
    "\n",
    "Data Understanding:\n",
    "Data Set: https://www.kaggle.com/fedesoriano/stroke-prediction-dataset\n",
    "Date Created: 01/26/2021\n",
    "The dataset has 12 columns and 5,110 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ad571e-a4ce-46cb-9456-86cb03c2b3d4",
   "metadata": {},
   "source": [
    "Data preparation:\n",
    "Python Version: 3.7.6\n",
    "Packages: Pandas, Numpy, Matplotlib, Seaborn, Sklearn, and imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a105ca7-f5bd-44fb-a98c-d37428b15d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score,classification_report,precision_score,recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592ed5e-3339-4d35-9615-6f0f31c65565",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('healthcare-dataset-stroke-data.csv') #Reading csv file\n",
    "data.head() # Displaying top 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1658c981-28da-49c4-899f-22b2ab783202",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104400b8-7076-4c8f-ae83-4776318ac207",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info() # Showing information about datase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444adf6a-5cd8-473a-b57b-9e3fdd091f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe() # Showing data's statistical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3066bd1-428e-4de4-8557-666794ec6668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ID is nothing but a unique number assigned to every patient to keep track of them and making them unique. So, dropping it.\n",
    "data.drop(\"id\",inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fef1c06-a178-46b0-8df2-feeee7f83d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender of the paitents\n",
    "print('Unique values\\n',data['gender'].unique())\n",
    "print('Value Counts\\n',data['gender'].value_counts())\n",
    "# Above codes will give us gender's unique values and count of each value.\n",
    "\n",
    "sns.countplot(data=data,x='gender') #This will help us to see count of values in each unique category.\n",
    "sns.countplot(data=data,x='gender',hue='stroke')# This plot will help to analyze how gender will affect chances of stroke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46f39f1-9fcc-41bf-9edc-294727f05943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age\n",
    "data['age'].nunique() # Returns number of unique values \n",
    "sns.displot(data['age']) # This will plot a distribution plot of variable age\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.countplot(data=data,x='age',hue='stroke') # This plot will help to analyze how gender will affect chances of stroke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29316283-0b86-47b4-9b9f-1ae0640ebf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previous heart diseases\n",
    "print('Unique Value\\n',data['heart_disease'].unique())\n",
    "print('Value Counts\\n',data['heart_disease'].value_counts())\n",
    "# Above code will gives us unique value for heart disease and its value counts\n",
    "sns.countplot(data=data,x='heart_disease') # Will plot a counter plot of variable heart diseases\n",
    "sns.countplot(data=data,x='heart_disease',hue='stroke') # This plot will help to analyze how gender will affect chances of stroke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e615f9a-5b32-4b3e-8c54-5a733f3b2388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypertensive paitents\n",
    "print('Unique Value\\n',data['heart_disease'].unique())\n",
    "print('Value Counts\\n',data['heart_disease'].value_counts())\n",
    "# Above code will gives us unique value for heart disease and its value counts\n",
    "sns.countplot(data=data,x='heart_disease') # Will plot a counter plot of variable heart diseases\n",
    "sns.countplot(data=data,x='heart_disease',hue='stroke') # This plot will help to analyze how gender will affect chances of stroke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fda60d8-7c01-4823-b0c3-31fbd2c66938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ever married in life \n",
    "print('Unique Values\\n',data['ever_married'].unique())\n",
    "print('Value Counts\\n',data['ever_married'].value_counts())\n",
    "# Above code will gives us number unique values of ever-married patients and its value count\n",
    "sns.countplot(data=data,x='ever_married') # Counter plot of ever married \n",
    "sns.countplot(data=data,x='ever_married',hue='stroke') # Ever married with respect of stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be684a-53fa-458a-9c24-b8d01ebf1d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Work type of patients\n",
    "print('Unique Value\\n',data['work_type'].unique())\n",
    "print('Value Counts\\n',data['work_type'].value_counts())\n",
    "# Above code will gives us unique values of work type and its value count\n",
    "sns.countplot(data=data,x='work_type') # Counter plot of work type\n",
    "sns.countplot(data=data,x='work_type',hue='stroke') # Count plot of work type with respect to stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a78d049-ed21-4a16-a4d5-37327e7c962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Residence type of paitents\n",
    "print('Unique Values\\n',data['Residence_type'].unique())\n",
    "print(\"Value Counts\\n\",data['Residence_type'].value_counts())\n",
    "# Above code will gives us unique values of Residence type and its count\n",
    "sns.countplot(data=data,x='Residence_type') # Counter plot of residence type\n",
    "sns.countplot(data=data,x='Residence_type',hue='stroke') # Residence Type with respect to stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769e21aa-4a81-4a14-8f4c-9dab3c5e15d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Body mass index - BMI\n",
    "data['bmi'].isna().sum() #Gives us the null values\n",
    "data['bmi'].fillna(data['bmi'].mean(),inplace=True) # Filling null values with average value\n",
    "data['bmi'].nunique() # Gives us the number of unique values \n",
    "sns.displot(data['bmi']) # Distribution of bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6389bee5-ba9c-49fc-8a76-8ae66ffdc3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoking status of patients\n",
    "print('Unique Values\\n',data['smoking_status'].unique())\n",
    "print('Value Counts\\n',data['smoking_status'].value_counts())\n",
    "# Gives us the unique values and its count\n",
    "sns.countplot(data=data,x='smoking_status') # Count plot of smoking status\n",
    "sns.countplot(data=data,x='smoking_status',hue='stroke') # Smoking Status with respect to Stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7170fd5-d2b5-4c54-bc70-c769c5e169d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stroke - Our target variable. It tells us whether patients have chances of stroke.\n",
    "print('Unique Value\\n',data['stroke'].unique())\n",
    "print('Value Counts\\n',data['stroke'].value_counts())\n",
    "# Gives us the unique Value and its count\n",
    "sns.countplot(data=data,x='stroke') # Count Plot of Stroke"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a0cb49-4c75-4a58-b1bb-fe7630356744",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dd025a-0297-49ed-bae9-15e51d6aa984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feteching columns whose data type is object.\n",
    "cols=data.select_dtypes(include=['object']).columns\n",
    "print(cols)\n",
    "le=LabelEncoder() # Initializing our Label Encoder object\n",
    "data[cols]=data[cols].apply(le.fit_transform) # Transfering categorical data into numeric\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2f9b7d-476a-4be1-a87a-77f34dfc8f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting heat map for checking correlation \n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(data.corr(),annot=True,fmt='.2')\n",
    "#We can see that age, hypertension, heart_disease, ever_married, avg_glucose_level have effective correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e109a9-7008-4594-bb45-a6525e2e162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To crsss check we will use - SelectKBest - used for extracting best features of given dataset\n",
    "#f_classif - Compute the ANOVA F-value for the provided sample.\n",
    "classifier = SelectKBest(score_func=f_classif,k=5)\n",
    "fits = classifier.fit(data.drop('stroke',axis=1),data['stroke'])\n",
    "x=pd.DataFrame(fits.scores_)\n",
    "columns = pd.DataFrame(data.drop('stroke',axis=1).columns)\n",
    "fscores = pd.concat([columns,x],axis=1)\n",
    "fscores.columns = ['Attribute','Score']\n",
    "fscores.sort_values(by='Score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50367d80-5159-44b8-95d7-eaf66e01c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see that age is having highest values so, we can keep threshold of 50\n",
    "cols=fscores[fscores['Score']>50]['Attribute']\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b415b57-dcc3-471b-b9eb-52ce3c979447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining independent and dependent variables\n",
    "X = data[cols]\n",
    "y = data['stroke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9785b42-2b27-4d59-a2dd-567b6cce59c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard scalar transforms the data in such a manner that it has mean as 0 and standard deviation as 1\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87215874-f743-43fb-8a31-9b8f6a8cc669",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea3c71c-77c0-4683-bdc6-616ac0f420ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHecking values of 0 and 1 in dataset\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y==0)))\n",
    "#creating new samples using existing one with help of smote function\n",
    "sm = SMOTE(random_state=2)\n",
    "X, y = sm.fit_resample(X, y.ravel())\n",
    "#checking values of X and y in dataset after oversampling \n",
    "print('After OverSampling, the shape of X: {}'.format(X.shape))\n",
    "print('After OverSampling, the shape of y: {} \\n'.format(y.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519e34ea-baf0-43a6-bc31-8108c6ecf4ee",
   "metadata": {},
   "source": [
    "Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3778cdca-872f-4846-bdb9-2f878e5f757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data in train and test \n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=50,test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f40c4-d065-47fe-b8af-89d211408442",
   "metadata": {},
   "source": [
    "Model 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914ad5ef-16af-425a-b7b1-a93ade04a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling logistic function \n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train) #fitting and training the model with traning values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c5d7c2-1705-49f8-a1db-ad94a5672392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating y_pred variable as model is predicting values with help of X-test data \n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbacecf8-5585-4335-8b52-ae0b60301c6f",
   "metadata": {},
   "source": [
    "Evaluation of Model 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8043f77-4692-44c1-8aa9-f0482d8f8e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling confusion matrix function because they give direct comparisons of values like True Positives, False Positives, True Negatives and False Negatives.\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dfc0fa-9385-49af-8bc6-48611b96e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm, figsize=(5, 5), cmap=plt.cm.Greens)\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a7c43-a0fd-49c2-8563-19048723b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a variable and assigning the accuracy score values with help of y_test and y_pred \n",
    "#Accuracy classification score - This function computes subset accuracy the y predicted for a sample must exactly match with the y_actual\n",
    "logreg=accuracy_score(y_test,y_pred) \n",
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febf90da-122c-46e7-9657-8bf5be16cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing roc and auc scores\n",
    "#OC is a probability curve and AUC represents the degree/measure of separability\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244880aa-5a54-460e-b016-0a58ebf37213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification report- Build a text report showing the main classification metrics.\n",
    "print(metrics.classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d89a76-da30-41ba-a5f1-0ea12b7ae4ed",
   "metadata": {},
   "source": [
    "Model 2 - Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0174e8b2-4c59-4603-834d-98f14bc02ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling decision tree classifier \n",
    "dt = DecisionTreeClassifier(criterion = 'entropy', random_state = 42)\n",
    "dt.fit(X_train, y_train) #fitting and training the model with traning values\n",
    "dt_pred_train = dt.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5034f60-bab9-4211-b47e-3b8aae13eeb1",
   "metadata": {},
   "source": [
    "Evaluation of Model 2 - Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e15ffe3-7a3f-46e9-a071-eb4369500395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing evaluation score usinf f-test for training data\n",
    "print('Training Set Evaluation F1-Score=> ', f1_score(y_train, dt_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c4e3fc-c20f-4203-be68-566051613086",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pred_test = dt.predict(X_test)\n",
    "#Printing evaluation score usinf f-test for test data\n",
    "print('Testing Set Evaluation F1-Score=> ', f1_score(y_test, dt_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd16736-e7ba-444c-ba08-b758ae8d4b45",
   "metadata": {},
   "source": [
    "Model 3 - Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33dd2f2-997a-445a-a57a-cc690e592ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Random Forest Classifier\n",
    "rfc = RandomForestClassifier(criterion = 'entropy', random_state = 42)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2417873d-ced0-4f24-9b9b-db3ab881f26e",
   "metadata": {},
   "source": [
    "Evaluation of Model 3 - Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530d03ff-cbab-4826-aa4c-aefb0009b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating on Training set\n",
    "rfc_pred_train = rfc.predict(X_train)\n",
    "print('Training Set Evaluation F1_score=> ', f1_score(y_train, rfc_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d180300f-1abe-4528-bd66-5da7f7b4a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred_test = rfc.predict(X_test)\n",
    "#Printing evaluation score usinf f-test for test data\n",
    "print('Testing Set Evaluation F1-Score=> ', f1_score(y_test, rfc_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7b6490-9289-45c9-89ca-f773510f7a61",
   "metadata": {},
   "source": [
    "Model 4 - Extreme Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588acb38-6ad8-4a71-a5d2-33b181b977e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Xgboost Classifier\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4799d797-db3b-436f-bbcf-7497b7b37fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluation of Model 4 - Extreme Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c659500-e226-4719-82f3-2b29b7de423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating on Training set\n",
    "print('Training Score: {}'.format(xgb_model.score(X_train, y_train))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0b49e8-1159-4b4e-a14f-8a0a6260eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating on test set\n",
    "print('Test Score: {}'.format(xgb_model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3477917a-ef5e-44b1-8a7d-4ea09c209701",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4151867a-e715-4d7c-b763-aaf2609dc2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing accuracy scores for xgboost\n",
    "logreg=accuracy_score(y_test,y_pred) \n",
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd0d71-e703-4c9c-9915-69b3fdd74997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing roc and auc scores for xgboost\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7613ca44-48c4-4869-81da-5439eb273745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification report for xgboost\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d4d6d4-ca19-4a38-bb67-86a2fe9b5914",
   "metadata": {},
   "source": [
    "As per the above models we can say, that the model 4 - Extreme Gradient Boosting has the higest accouracy for both training and test data set.\n",
    "So, we can use the same model for our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89253751-0be1-4f7c-bf60-20c3e50bc121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
